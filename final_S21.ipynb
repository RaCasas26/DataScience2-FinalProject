{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_S21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaCasas26/DataScience2-FinalProject/blob/main/final_S21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNlpEYHNjcT_"
      },
      "source": [
        "#  Final Project\n",
        "## Data Science (masters)\n",
        "## Math 5364 & 5366, Fall 20 & Spring 21\n",
        "## Tarleton State University\n",
        "## Dr. Scott Cook\n",
        "## Due 2021-05-14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05beGOpEJggA"
      },
      "source": [
        "## Background\n",
        "\n",
        "In North America, Monarch butterflies (*Danaus plexippus*) are one of the many species of insects that migrate during the winter. However, Monarch butterflies that inhabit other regions such as the Pacific or South America are known to not migrate. A study by Freedman et al. (2020) considers the differences in physical traits between nonmigratory and migratory Monarch butterflies. Specifically, the reserachers of this study compared the differences betweens in the forewing length between Monarch butterflies in North America, the Pacific, the Atlantic, South America, and Australia. By conducting a time series analyses on data collected since 1856, the researchers determined that not only did migratory Monarch butterflies have larger forewings than their nonmigratory counterparts but that the wing size of nonmigratory butterflies reduced over a period of 1000 years.\n",
        "\n",
        "The dataset appied in this study that considered several variables pertaining to the physical characteristics of different Monarch butterfly samples caught in the wild and in captivity throughout North America, South America, and Australia as well as throughout the Pacific and Atlantic regions. To explore potential models from this dataset, classifiers and regressors were considered in predicting the area a Monarch butterfly comes from as well as in predicting the era the butterfly was caught based off of the physical traits given in this study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXCBNKYzUARp"
      },
      "source": [
        "## Data Processing and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrV6I7kE-HFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198b1e57-cd8a-458e-95c5-af7a860631dc"
      },
      "source": [
        "! pip install --upgrade numpy\n",
        "! pip install --upgrade pandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.7/dist-packages (1.20.3)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.7/dist-packages (1.2.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.20.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5MUvP7dpJzC",
        "outputId": "88e44e93-e1eb-4559-c63c-f6b4538ae331"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "from copy import deepcopy  \n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.svm import LinearSVC, LinearSVR\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', 25)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFoQJikA-55f"
      },
      "source": [
        "# Find the wings_04.25.20.csv file in the Files menu on the left\n",
        "# Right click the file and click Copy Path\n",
        "# Paste the path between the quotation marks below\n",
        "path = \"/content/drive/MyDrive/Data_ScienceS21_Final/wings_04.25.20.csv\"\n",
        "df = pd.read_csv(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SybTFd3p0lHi"
      },
      "source": [
        "### Dataset\n",
        "The dataset given has 5367 data points with a total of 53 variables. Of those variables, the ones of interest were the region and country the butterfly was collected, the sex of the butterfly, and the butterfly's forewing measurements. As a result, only 25 variables were considered in the making of the models. \\\\\n",
        "Many values were missing in this dataset so many observations had to be removed or imputed. Since butterfly wings are symmetric, measurements for the left forewing were replaced with the measurements of the right forewing if any of those values were missing and vice versa if measurements of the right forewing were missing. If both measurements were missing, the observation was dropped from the dataset. \\\\\n",
        "The study by Freedman et al. (2020) applied PCA to the forewing length, width, and area to create the size principal conponenent which accounted for 96.4% of the forewing size variation and the study applied PCA to the forewing aspect ratio and roundness to create the shape principal component which accounted for 86% of the forewing shape variation. These principal components were created in a similar fashion in order to be applied to the analysis. \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZf2aqA_YGZB"
      },
      "source": [
        "df_orig = df.copy()\n",
        "\n",
        "#Removes variables not involved in analysis\n",
        "df = df.drop(['Index','SampleID','Collection', 'Island/State', 'County/District', 'Site/City', 'exact_location?',\n",
        "       'lon', 'Wild-Caught?', 'image_type', 'smoothing', 'Host_plant','observer'], axis=1)\n",
        "\n",
        "#Converts date into year from its original format (YYYYDDMM)\n",
        "df['Collection_Year'] = (df['Collection_Date'] * 10 ** (-4)).round(0)\n",
        "#Removes Collection Date which will not be used in the analysis\n",
        "df = df.drop('Collection_Date', axis=1)\n",
        "\n",
        "#Removes the gyandromorph sex so that only male and female monarch butterlies are considered for the analysis\n",
        "df = df[df['Sex'] != \"gyandromorph\"]\n",
        "\n",
        "#Removes observations which had no location of capture \n",
        "df = df[pd.notna(df['Region'])]\n",
        "#Removes observations in the Indian Ocean which are too few for analysis\n",
        "df = df[df['Region'] != 'Indian_Ocean']\n",
        "\n",
        "#Binarizes the sexes\n",
        "df = df.replace(to_replace={'male': 0, 'female': 1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evRW46Ohz3zx"
      },
      "source": [
        "vals = ['Length', 'Width', 'Area', 'Perimeter']\n",
        "for v in vals:\n",
        "    cols = [f'{s}{v}' for s in ['L', 'R']]\n",
        "    f = np.nanmean(df[cols], axis=1)\n",
        "    # print(f)\n",
        "    for c in cols:\n",
        "        mask = df[c].isnull()\n",
        "        df.loc[mask, c] = f[mask]\n",
        "    df.dropna(subset=cols, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi1TCZ3z-mvx"
      },
      "source": [
        "#Calculates Aspect Ration and Roundness of left and right forewings, respectively\n",
        "df['LAspect_Ratio'] = df['LLength']/df['LWidth']\n",
        "df['RAspect_Ratio'] = df['RLength']/df['RWidth']\n",
        "df['LRoundness'] = 4*np.pi*df['LArea'] / df['LPerimeter'] ** 2\n",
        "df['RRoundness'] = 4*np.pi*df['RArea'] / df['RPerimeter'] ** 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSLg7mY7f328"
      },
      "source": [
        "#Binarizes the 'overwintering?' variable\n",
        "df = df.replace(to_replace={'no': 0, 'yes': 1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcYrmawOBmN7"
      },
      "source": [
        "df = pd.DataFrame(df.to_numpy(), columns=['Region', 'Country/Archipelago', 'lat', 'overwintering?', 'Sex',\n",
        "       'LLength', 'LWidth', 'LArea', 'LPerimeter', 'RLength', 'RWidth',\n",
        "       'RArea', 'RPerimeter', 'Collection_Year', 'LAspect_Ratio',\n",
        "       'RAspect_Ratio', 'LRoundness', 'RRoundness'])\n",
        "df[['lat', 'overwintering?', 'Sex','LLength', 'LWidth', 'LArea', 'LPerimeter', 'RLength', 'RWidth',\n",
        "       'RArea', 'RPerimeter', 'Collection_Year', 'LAspect_Ratio',\n",
        "       'RAspect_Ratio', 'LRoundness', 'RRoundness']] = df[['lat', 'overwintering?', 'Sex','LLength', 'LWidth', 'LArea', 'LPerimeter', 'RLength', 'RWidth',\n",
        "       'RArea', 'RPerimeter', 'Collection_Year', 'LAspect_Ratio',\n",
        "       'RAspect_Ratio', 'LRoundness', 'RRoundness']].astype('float64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG7LaelOLwM1"
      },
      "source": [
        "#Applies PCA to compute the first components describing size and shape as described in Freedman et al. (2020)\n",
        "SizePC1 = pd.DataFrame(PCA(n_components=1, random_state=42).fit_transform(df[['LLength', 'LWidth', 'LArea', 'RLength', 'RWidth', 'RArea']]), columns= ['SizePC1'])\n",
        "ShapePC1 = pd.DataFrame(PCA(n_components=1, random_state=42).fit_transform(df[['LAspect_Ratio','RAspect_Ratio', 'LRoundness', 'RRoundness']]), columns= ['ShapePC1'])\n",
        "df = pd.concat([df.reindex(index=ShapePC1.index), ShapePC1, SizePC1], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "hTzaKuYai81O",
        "outputId": "06d0cb72-9759-4a1b-c335-879e10c42b47"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lat</th>\n",
              "      <th>overwintering?</th>\n",
              "      <th>Sex</th>\n",
              "      <th>LLength</th>\n",
              "      <th>LWidth</th>\n",
              "      <th>LArea</th>\n",
              "      <th>LPerimeter</th>\n",
              "      <th>RLength</th>\n",
              "      <th>RWidth</th>\n",
              "      <th>RArea</th>\n",
              "      <th>RPerimeter</th>\n",
              "      <th>Collection_Year</th>\n",
              "      <th>LAspect_Ratio</th>\n",
              "      <th>RAspect_Ratio</th>\n",
              "      <th>LRoundness</th>\n",
              "      <th>RRoundness</th>\n",
              "      <th>ShapePC1</th>\n",
              "      <th>SizePC1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6560.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.00000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6123.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6589.000000</td>\n",
              "      <td>6.589000e+03</td>\n",
              "      <td>6.589000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.310120</td>\n",
              "      <td>0.044316</td>\n",
              "      <td>0.444377</td>\n",
              "      <td>4.911631</td>\n",
              "      <td>2.506502</td>\n",
              "      <td>8.004036</td>\n",
              "      <td>11.779823</td>\n",
              "      <td>4.926687</td>\n",
              "      <td>2.50809</td>\n",
              "      <td>8.042228</td>\n",
              "      <td>11.820600</td>\n",
              "      <td>1961.449943</td>\n",
              "      <td>1.960393</td>\n",
              "      <td>1.965098</td>\n",
              "      <td>0.722211</td>\n",
              "      <td>0.720750</td>\n",
              "      <td>-8.154174e-17</td>\n",
              "      <td>9.608678e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>25.139305</td>\n",
              "      <td>0.205812</td>\n",
              "      <td>0.496934</td>\n",
              "      <td>0.356998</td>\n",
              "      <td>0.177482</td>\n",
              "      <td>1.061390</td>\n",
              "      <td>0.850554</td>\n",
              "      <td>0.359470</td>\n",
              "      <td>0.17692</td>\n",
              "      <td>1.061425</td>\n",
              "      <td>0.853559</td>\n",
              "      <td>34.949535</td>\n",
              "      <td>0.066570</td>\n",
              "      <td>0.067042</td>\n",
              "      <td>0.020638</td>\n",
              "      <td>0.021711</td>\n",
              "      <td>9.180988e-02</td>\n",
              "      <td>1.589064e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-40.857807</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.211000</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>3.542000</td>\n",
              "      <td>7.731000</td>\n",
              "      <td>2.935000</td>\n",
              "      <td>1.67000</td>\n",
              "      <td>3.606000</td>\n",
              "      <td>7.806000</td>\n",
              "      <td>1856.000000</td>\n",
              "      <td>1.546780</td>\n",
              "      <td>1.000341</td>\n",
              "      <td>0.570151</td>\n",
              "      <td>0.583013</td>\n",
              "      <td>-6.625055e-01</td>\n",
              "      <td>-6.088675e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-6.801374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.709000</td>\n",
              "      <td>2.407000</td>\n",
              "      <td>7.386000</td>\n",
              "      <td>11.299000</td>\n",
              "      <td>4.722000</td>\n",
              "      <td>2.41100</td>\n",
              "      <td>7.421000</td>\n",
              "      <td>11.338000</td>\n",
              "      <td>1935.000000</td>\n",
              "      <td>1.919387</td>\n",
              "      <td>1.922643</td>\n",
              "      <td>0.709687</td>\n",
              "      <td>0.708001</td>\n",
              "      <td>-5.638972e-02</td>\n",
              "      <td>-1.080165e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>18.109580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.951000</td>\n",
              "      <td>2.525000</td>\n",
              "      <td>8.087000</td>\n",
              "      <td>11.870000</td>\n",
              "      <td>4.972000</td>\n",
              "      <td>2.52500</td>\n",
              "      <td>8.130000</td>\n",
              "      <td>11.922000</td>\n",
              "      <td>1965.000000</td>\n",
              "      <td>1.959316</td>\n",
              "      <td>1.964615</td>\n",
              "      <td>0.722689</td>\n",
              "      <td>0.721771</td>\n",
              "      <td>-8.371775e-04</td>\n",
              "      <td>-1.364584e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.315741</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.158000</td>\n",
              "      <td>2.626000</td>\n",
              "      <td>8.725000</td>\n",
              "      <td>12.371000</td>\n",
              "      <td>5.178000</td>\n",
              "      <td>2.63000</td>\n",
              "      <td>8.771000</td>\n",
              "      <td>12.419000</td>\n",
              "      <td>1984.000000</td>\n",
              "      <td>2.000390</td>\n",
              "      <td>2.005702</td>\n",
              "      <td>0.735385</td>\n",
              "      <td>0.734510</td>\n",
              "      <td>5.422625e-02</td>\n",
              "      <td>9.176677e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>52.920633</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.033000</td>\n",
              "      <td>3.219000</td>\n",
              "      <td>12.184000</td>\n",
              "      <td>14.685000</td>\n",
              "      <td>6.011000</td>\n",
              "      <td>3.21500</td>\n",
              "      <td>12.110000</td>\n",
              "      <td>14.653000</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>2.803137</td>\n",
              "      <td>2.484677</td>\n",
              "      <td>0.801186</td>\n",
              "      <td>0.800982</td>\n",
              "      <td>9.340516e-01</td>\n",
              "      <td>6.841371e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               lat  overwintering?          Sex      LLength       LWidth  \\\n",
              "count  6560.000000     6589.000000  6589.000000  6589.000000  6589.000000   \n",
              "mean     13.310120        0.044316     0.444377     4.911631     2.506502   \n",
              "std      25.139305        0.205812     0.496934     0.356998     0.177482   \n",
              "min     -40.857807        0.000000     0.000000     3.211000     1.625000   \n",
              "25%      -6.801374        0.000000     0.000000     4.709000     2.407000   \n",
              "50%      18.109580        0.000000     0.000000     4.951000     2.525000   \n",
              "75%      35.315741        0.000000     1.000000     5.158000     2.626000   \n",
              "max      52.920633        1.000000     1.000000     6.033000     3.219000   \n",
              "\n",
              "             LArea   LPerimeter      RLength      RWidth        RArea  \\\n",
              "count  6589.000000  6589.000000  6589.000000  6589.00000  6589.000000   \n",
              "mean      8.004036    11.779823     4.926687     2.50809     8.042228   \n",
              "std       1.061390     0.850554     0.359470     0.17692     1.061425   \n",
              "min       3.542000     7.731000     2.935000     1.67000     3.606000   \n",
              "25%       7.386000    11.299000     4.722000     2.41100     7.421000   \n",
              "50%       8.087000    11.870000     4.972000     2.52500     8.130000   \n",
              "75%       8.725000    12.371000     5.178000     2.63000     8.771000   \n",
              "max      12.184000    14.685000     6.011000     3.21500    12.110000   \n",
              "\n",
              "        RPerimeter  Collection_Year  LAspect_Ratio  RAspect_Ratio  \\\n",
              "count  6589.000000      6123.000000    6589.000000    6589.000000   \n",
              "mean     11.820600      1961.449943       1.960393       1.965098   \n",
              "std       0.853559        34.949535       0.066570       0.067042   \n",
              "min       7.806000      1856.000000       1.546780       1.000341   \n",
              "25%      11.338000      1935.000000       1.919387       1.922643   \n",
              "50%      11.922000      1965.000000       1.959316       1.964615   \n",
              "75%      12.419000      1984.000000       2.000390       2.005702   \n",
              "max      14.653000      2018.000000       2.803137       2.484677   \n",
              "\n",
              "        LRoundness   RRoundness      ShapePC1       SizePC1  \n",
              "count  6589.000000  6589.000000  6.589000e+03  6.589000e+03  \n",
              "mean      0.722211     0.720750 -8.154174e-17  9.608678e-16  \n",
              "std       0.020638     0.021711  9.180988e-02  1.589064e+00  \n",
              "min       0.570151     0.583013 -6.625055e-01 -6.088675e+00  \n",
              "25%       0.709687     0.708001 -5.638972e-02 -1.080165e+00  \n",
              "50%       0.722689     0.721771 -8.371775e-04 -1.364584e-01  \n",
              "75%       0.735385     0.734510  5.422625e-02  9.176677e-01  \n",
              "max       0.801186     0.800982  9.340516e-01  6.841371e+00  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5Ju-H7OsFHb"
      },
      "source": [
        "Several different questions were considered in the analysis of the dataset:\n",
        "    \n",
        "    1. Could physical traits and sex help determine the region the Monarch butterfly was collected?\n",
        "    2. Could physical traits and sex help determine the country the Monarch butterfly was collected?\n",
        "    3. Could physical traits and sex help determine where in North America migratory butterflies were originally from? \n",
        "    4. Could physical traits, sex, and region help determine what year the butterfly was collected? \n",
        "\n",
        "To answer each of these questions, the dataframes were formated to exclude missing values from the target variables and to exclude classes with fewer that 5 observations to aviod issues with the algorithms. All models included the shape and size principal components and the sex of the Monarch butterfly as the predicting variables. Only the model for question 4 inlcuded the region as a predicting variable. \n",
        "The dataset for each model was split into modeling and holdouts sets in which 80% of the data was allocated into the modeling set and 20% of the data was allocated into the holdout set using a stratified shuffle split algorithm for the classifiers and a shuffle split algorithm for the regressor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQfm3dvL20qK"
      },
      "source": [
        "#Modelling datasets for predicting region based on physical traits\n",
        "df_reg = df[pd.notna(df['Region'])]\n",
        "X_reg = df_reg[['ShapePC1', 'SizePC1' ,'Sex']]\n",
        "y_reg = df_reg['Region']\n",
        "\n",
        "holdout_frac = 0.20\n",
        "holdout_splitter = StratifiedShuffleSplit(test_size=holdout_frac, random_state=42)\n",
        "model_idx, holdout_idx = next(holdout_splitter.split(X_reg, y_reg))\n",
        "X_reg_m, y_reg_m = X_reg.iloc[model_idx]  , y_reg.iloc[model_idx]\n",
        "X_reg_h, y_reg_h = X_reg.iloc[holdout_idx], y_reg.iloc[holdout_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDY7vqH-4vTX"
      },
      "source": [
        "#Modelling datasets for predicting country based on physical traits\n",
        "df_country = df[pd.notna(df['Country/Archipelago'])]\n",
        "df_country = df_country[(df['Country/Archipelago'] != 'Tokelau') & \n",
        "                (df['Country/Archipelago'] != 'Cape_Verde') &\n",
        "                (df['Country/Archipelago'] != 'Philippines') &\n",
        "                (df['Country/Archipelago'] != 'Argentina') &\n",
        "                (df['Country/Archipelago'] != 'Saint_Lucia') &\n",
        "                (df['Country/Archipelago'] != 'Kiribati') &\n",
        "                (df['Country/Archipelago'] != 'Palau') &\n",
        "                (df['Country/Archipelago'] != 'Kermedec_Islands') &\n",
        "                (df['Country/Archipelago'] != 'Tobago') &\n",
        "                (df['Country/Archipelago'] != 'Marshall_Islands') &\n",
        "                (df['Country/Archipelago'] != 'French_Guyana') &\n",
        "                (df['Country/Archipelago'] != 'Belize') &\n",
        "                (df['Country/Archipelago'] != 'Azores') &\n",
        "                (df['Country/Archipelago'] != 'Cook_Islands') &\n",
        "                (df['Country/Archipelago'] != 'Bermuda') &\n",
        "                (df['Country/Archipelago'] != 'Taiwan') &\n",
        "                (df['Country/Archipelago'] != 'Marquesas')]\n",
        "#group by, filter\n",
        "X_ctry = df_country[['ShapePC1', 'SizePC1' ,'Sex']]\n",
        "y_ctry = df_country['Country/Archipelago']\n",
        "\n",
        "holdout_frac = 0.20\n",
        "holdout_splitter = StratifiedShuffleSplit(n_splits = 5, test_size=holdout_frac, random_state=42)\n",
        "model_idx, holdout_idx = next(holdout_splitter.split(X_ctry, y_ctry))\n",
        "X_ctry_m, y_ctry_m = X_ctry.iloc[model_idx]  , y_ctry.iloc[model_idx]\n",
        "X_ctry_h, y_ctry_h = X_ctry.iloc[holdout_idx], y_ctry.iloc[holdout_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8817Pox47ye"
      },
      "source": [
        "#Modelling datasets for predicting the origin of migratory butterflies in North America based on physical traits\n",
        "df_lat = df[pd.notna(df['lat'])]\n",
        "df_lat = df_lat[(df_lat['Region'] == 'North_America') & (df_lat['overwintering?'] == 0)]\n",
        "\n",
        "X_lat = df_lat[['ShapePC1', 'SizePC1' ,'Sex']]\n",
        "y_lat = df_lat['lat']\n",
        "\n",
        "holdout_frac = 0.20\n",
        "holdout_splitter = ShuffleSplit(test_size=holdout_frac, random_state=42)\n",
        "model_idx, holdout_idx = next(holdout_splitter.split(X_lat, y_lat))\n",
        "X_lat_m, y_lat_m = X_lat.iloc[model_idx]  , y_lat.iloc[model_idx]\n",
        "X_lat_h, y_lat_h = X_lat.iloc[holdout_idx], y_lat.iloc[holdout_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI8LSqMl5IrU"
      },
      "source": [
        "#Modelling datasets for predicting year based on physical traits and region\n",
        "df_yr = df[pd.notna(df['Collection_Year'])]\n",
        "df_yr = pd.concat([df_yr, pd.get_dummies(df_yr['Region']).astype('float64')], axis = 1).reindex(df_yr.index)\n",
        "\n",
        "X_yr = df_yr[['ShapePC1', 'SizePC1' ,'Sex', 'Atlantic', 'Caribbean', 'Central_America', 'North_America',\n",
        "       'Pacific_Islands', 'South_America']]\n",
        "y_yr = df_yr['Collection_Year']\n",
        "\n",
        "holdout_frac = 0.20\n",
        "holdout_splitter = ShuffleSplit(test_size=holdout_frac, random_state=42)\n",
        "model_idx, holdout_idx = next(holdout_splitter.split(X_yr, y_yr))\n",
        "X_yr_m, y_yr_m = X_yr.iloc[model_idx]  , y_yr.iloc[model_idx]\n",
        "X_yr_h, y_yr_h = X_yr.iloc[holdout_idx], y_yr.iloc[holdout_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaW-Spx01sUa"
      },
      "source": [
        "## Supervised Model Building and Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgilowL7seOr"
      },
      "source": [
        "The classifiers applied were the K-Nearest Neighbors classifier, the Random Forest classifier, and the Linear Support Vector Machine classifier. For all models, three different scalers were used to transform the data. Those being the standard scaler, the min-max scaler, and the robust scalers.\n",
        " \n",
        "For the K-Nearest Neighbor classifier, the hyperparameters of interest were the number of neighbors and the weight function used for the prediction. The number of neighbors chosen were multiples of 5 up until 25 and the weight functions considered were the uniform and distance weight functions. \n",
        "\n",
        "For the Random Forest classifier, the hyperparameter of interest was the maximum depth of each decision tree. The maximum depth of each decision tree were multiples of 2 up until 10.\n",
        "\n",
        "For the Linear Support Vector Machine classifier, the hyperparameter of interest was the regularization parameter, $C$. The parameter $C$ was given by 5 equally spaced points from 0.5 to 3.\n",
        "\n",
        "For each model, k-fold cross validation was performed using the weighted $F1$-score as a performance metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lymaqqH-iUdE"
      },
      "source": [
        "class TopModel_Classifier:\n",
        "    def __init__(self, X_m, y_m):\n",
        "        self.X_m = X_m\n",
        "        self.y_m = y_m\n",
        "\n",
        "    def top_knc(self):\n",
        "        scaler_type = [StandardScaler, MinMaxScaler, RobustScaler]\n",
        "        grid_k = {}\n",
        "        for s in scaler_type:\n",
        "            pipe = Pipeline([('scale', s()),\n",
        "                            ('classify'  , KNeighborsClassifier())\n",
        "                            ])\n",
        "\n",
        "            hyperparams = {\n",
        "                        'classify__n_neighbors' : np.concatenate((np.arange(1,2), np.arange(5,26,5)), axis = None),\n",
        "                        'classify__weights' : ['uniform', 'distance']\n",
        "                        }\n",
        "            grid_k[\"grid_\" + s.__name__] = GridSearchCV(pipe, hyperparams, cv=10, scoring='f1_weighted').fit(self.X_m, self.y_m)\n",
        "        res1 = grid_k[\"grid_StandardScaler\"].cv_results_\n",
        "        df1 = pd.DataFrame(res1['params'])\n",
        "        df1['score'] = res1['mean_test_score']\n",
        "        df1['scale'] = 'standard'\n",
        "\n",
        "        res2 = grid_k[\"grid_MinMaxScaler\"].cv_results_\n",
        "        df2 = pd.DataFrame(res2['params'])\n",
        "        df2['score'] = res2['mean_test_score']\n",
        "        df2['scale'] = 'min_max'\n",
        "\n",
        "        res3 = grid_k[\"grid_RobustScaler\"].cv_results_\n",
        "        df3 = pd.DataFrame(res3['params'])\n",
        "        df3['score'] = res3['mean_test_score']\n",
        "        df3['scale'] = 'robust'\n",
        "\n",
        "        res = [df1, df2, df3]\n",
        "        df = pd.concat(res, ignore_index = True)\n",
        "        M = df['score'].quantile(q = 0.95)\n",
        "        mask = df['score'] > M\n",
        "        return df[mask].sort_values(by = 'score', ascending = False)\n",
        "\n",
        "    def top_rfc(self):\n",
        "        scaler_type = [StandardScaler, MinMaxScaler, RobustScaler]\n",
        "        grid_k = {}\n",
        "        for s in scaler_type:\n",
        "            pipe = Pipeline([('scale', s()),\n",
        "                            ('classify' , RandomForestClassifier(random_state=42))\n",
        "                            ])\n",
        "\n",
        "            hyperparams = {\n",
        "                        'classify__max_depth' : np.arange(2, 11, 2)\n",
        "                        }\n",
        "            grid_k[\"grid_\" + s.__name__] = GridSearchCV(pipe, hyperparams, cv=10, scoring='f1_weighted').fit(self.X_m, self.y_m)\n",
        "        res1 = grid_k[\"grid_StandardScaler\"].cv_results_\n",
        "        df1 = pd.DataFrame(res1['params'])\n",
        "        df1['score'] = res1['mean_test_score']\n",
        "        df1['scale'] = 'standard'\n",
        "\n",
        "        res2 = grid_k[\"grid_MinMaxScaler\"].cv_results_\n",
        "        df2 = pd.DataFrame(res2['params'])\n",
        "        df2['score'] = res2['mean_test_score']\n",
        "        df2['scale'] = 'min_max'\n",
        "\n",
        "\n",
        "        res3 = grid_k[\"grid_RobustScaler\"].cv_results_\n",
        "        df3 = pd.DataFrame(res3['params'])\n",
        "        df3['score'] = res3['mean_test_score']\n",
        "        df3['scale'] = 'robust'\n",
        "\n",
        "        res = [df1, df2, df3]\n",
        "        df = pd.concat(res, ignore_index = True)\n",
        "\n",
        "        M = df['score'].quantile(q = 0.95)\n",
        "        mask = df['score'] > M\n",
        "        return df[mask].sort_values(by = 'score', ascending = False)\n",
        "\n",
        "    def top_lsvc(self):\n",
        "        scaler_type = [StandardScaler, MinMaxScaler, RobustScaler]\n",
        "        grid_k = {}\n",
        "        for s in scaler_type:\n",
        "            pipe = Pipeline([('scale', s()),\n",
        "                            ('classify' , LinearSVC(random_state=42))\n",
        "                            ])\n",
        "\n",
        "            hyperparams = {\n",
        "                            'classify__C': np.arange(0.5, 3.5,0.5)\n",
        "                        }\n",
        "            grid_k[\"grid_\" + s.__name__] = GridSearchCV(pipe, hyperparams, cv=10, scoring='f1_weighted').fit(self.X_m, self.y_m)\n",
        "        res1 = grid_k[\"grid_StandardScaler\"].cv_results_\n",
        "        df1 = pd.DataFrame(res1['params'])\n",
        "        df1['score'] = res1['mean_test_score']\n",
        "        df1['scale'] = 'standard'\n",
        "\n",
        "        res2 = grid_k[\"grid_MinMaxScaler\"].cv_results_\n",
        "        df2 = pd.DataFrame(res2['params'])\n",
        "        df2['score'] = res2['mean_test_score']\n",
        "        df2['scale'] = 'min_max'\n",
        "\n",
        "\n",
        "        res3 = grid_k[\"grid_RobustScaler\"].cv_results_\n",
        "        df3 = pd.DataFrame(res3['params'])\n",
        "        df3['score'] = res3['mean_test_score']\n",
        "        df3['scale'] = 'robust'\n",
        "\n",
        "        res = [df1, df2, df3]\n",
        "        df = pd.concat(res, ignore_index = True)\n",
        "\n",
        "        M = df['score'].quantile(q = 0.95)\n",
        "        mask = df['score'] > M\n",
        "        return df[mask].sort_values(by = 'score', ascending = False)\n",
        "\n",
        "    def best_model(self):\n",
        "        knc_model = self.top_knc()\n",
        "        knc_model['model'] = 'knc'\n",
        "        rfc_model = self.top_rfc()\n",
        "        rfc_model['model'] = 'rfc'\n",
        "        lsvc_model = self.top_lsvc()\n",
        "        lsvc_model['model'] = 'lsvc'\n",
        "\n",
        "        mask1 = knc_model['score'] == knc_model['score'].max()\n",
        "        mask2 = rfc_model['score'] == rfc_model['score'].max()\n",
        "        mask3 = lsvc_model['score'] == lsvc_model['score'].max()\n",
        "\n",
        "        full_model = [knc_model[mask1], rfc_model[mask2], lsvc_model[mask3]]\n",
        "        first_highest_score = [knc_model[mask1]['score'].iloc[0], rfc_model[mask2]['score'].iloc[0], lsvc_model[mask3]['score'].iloc[0]]\n",
        "        return full_model[np.argmax(first_highest_score)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "K8wXGdTA_5v9",
        "outputId": "9a1181a4-f1fe-4868-8152-1cda4e369bf4"
      },
      "source": [
        "TopModel_Classifier(X_reg_m,y_reg_m).best_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classify__max_depth</th>\n",
              "      <th>score</th>\n",
              "      <th>scale</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>8</td>\n",
              "      <td>0.437708</td>\n",
              "      <td>robust</td>\n",
              "      <td>rfc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    classify__max_depth     score   scale model\n",
              "13                    8  0.437708  robust   rfc"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "YET-NNp5_5ew",
        "outputId": "6e515988-a7bc-4802-f470-bcd157118893"
      },
      "source": [
        "TopModel_Classifier(X_ctry_m,y_ctry_m).best_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classify__n_neighbors</th>\n",
              "      <th>classify__weights</th>\n",
              "      <th>score</th>\n",
              "      <th>scale</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.225223</td>\n",
              "      <td>min_max</td>\n",
              "      <td>knc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    classify__n_neighbors classify__weights     score    scale model\n",
              "20                     20           uniform  0.225223  min_max   knc"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6-Ar9Bi7yhw"
      },
      "source": [
        "The regressors applied were the K-Nearest Neighbors regressor, the Random Forest regressor, the Linear Support Vector Machine regressor, the LASSO regressor and the Ridge regressor. For all models, three different scalers were used to transform the data. Those being the standard scaler, the min-max scaler, and the robust scalers.\n",
        " \n",
        "For the K-Nearest Neighbor regressor, the hyperparameters of interest were the number of neighbors and the weight function used for the prediction. The number of neighbors chosen were multiples of 5 up until 25 and the weight functions considered were the uniform and distance weight functions. \n",
        "\n",
        "For the Random Forest regressor, the hyperparameter of interest was the maximum depth of each decision tree. The maximum depth of each decision tree were multiples of 2 up until 10.\n",
        "\n",
        "For the Linear Support Vector Machine regressor, the hyperparameter of interest was the regularization parameter, $C$. The parameter $C$ was given by 5 equally spaced points from 0.5 to 3.\n",
        "\n",
        "For the LASSO and Ridge regressors, the hyperparameter of interest was the coefficient penalty, $\\alpha$. The paramter $\\alpha$ was given by 9 equally spaced points from 0.2 to 2.\n",
        "\n",
        "For each model, k-fold cross validation was performed using $R^2$ as a performance metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp5EpdXwxNyk"
      },
      "source": [
        "class TopModel_Regressor:\n",
        "    def __init__(self, X_m, y_m):\n",
        "        self.X_m = X_m\n",
        "        self.y_m = y_m\n",
        "\n",
        "    def top_knr(self):\n",
        "        scaler_type = [StandardScaler, MinMaxScaler, RobustScaler]\n",
        "        grid_k = {}\n",
        "        for s in scaler_type:\n",
        "            pipe = Pipeline([('scale', s()),\n",
        "                            ('classify'  , KNeighborsRegressor())\n",
        "                            ])\n",
        "\n",
        "            hyperparams = {\n",
        "                        'classify__n_neighbors' : np.concatenate((np.arange(1,2), np.arange(5,26,5)), axis = None),\n",
        "                        'classify__weights' : ['uniform', 'distance']\n",
        "                        }\n",
        "            grid_k[\"grid_\" + s.__name__] = GridSearchCV(pipe, hyperparams, cv=10, scoring='r2').fit(self.X_m, self.y_m)\n",
        "        res1 = grid_k[\"grid_StandardScaler\"].cv_results_\n",
        "        df1 = pd.DataFrame(res1['params'])\n",
        "        df1['score'] = res1['mean_test_score']\n",
        "        df1['scale'] = 'standard'\n",
        "\n",
        "        res2 = grid_k[\"grid_MinMaxScaler\"].cv_results_\n",
        "        df2 = pd.DataFrame(res2['params'])\n",
        "        df2['score'] = res2['mean_test_score']\n",
        "        df2['scale'] = 'min_max'\n",
        "\n",
        "        res3 = grid_k[\"grid_RobustScaler\"].cv_results_\n",
        "        df3 = pd.DataFrame(res3['params'])\n",
        "        df3['score'] = res3['mean_test_score']\n",
        "        df3['scale'] = 'robust'\n",
        "\n",
        "        res = [df1, df2, df3]\n",
        "        df = pd.concat(res, ignore_index = True)\n",
        "        M = df['score'].quantile(q = 0.95)\n",
        "        mask = df['score'] > M\n",
        "        return df[mask].sort_values(by = 'score', ascending = False)\n",
        "\n",
        "    def top_rfr(self):\n",
        "        scaler_type = [StandardScaler, MinMaxScaler, RobustScaler]\n",
        "        grid_k = {}\n",
        "        for s in scaler_type:\n",
        "            pipe = Pipeline([('scale', s()),\n",
        "                            ('classify' , RandomForestRegressor(random_state=42))\n",
        "                            ])\n",
        "\n",
        "            hyperparams = {\n",
        "                        'classify__max_depth' : np.arange(2, 11, 2)\n",
        "                        }\n",
        "            grid_k[\"grid_\" + s.__name__] = GridSearchCV(pipe, hyperparams, cv=10, scoring='r2').fit(self.X_m, self.y_m)\n",
        "        res1 = grid_k[\"grid_StandardScaler\"].cv_results_\n",
        "        df1 = pd.DataFrame(res1['params'])\n",
        "        df1['score'] = res1['mean_test_score']\n",
        "        df1['scale'] = 'standard'\n",
        "\n",
        "        res2 = grid_k[\"grid_MinMaxScaler\"].cv_results_\n",
        "        df2 = pd.DataFrame(res2['params'])\n",
        "        df2['score'] = res2['mean_test_score']\n",
        "        df2['scale'] = 'min_max'\n",
        "\n",
        "\n",
        "        res3 = grid_k[\"grid_RobustScaler\"].cv_results_\n",
        "        df3 = pd.DataFrame(res3['params'])\n",
        "        df3['score'] = res3['mean_test_score']\n",
        "        df3['scale'] = 'robust'\n",
        "\n",
        "        res = [df1, df2, df3]\n",
        "        df = pd.concat(res, ignore_index = True)\n",
        "\n",
        "        M = df['score'].quantile(q = 0.95)\n",
        "        mask = df['score'] > M\n",
        "        return df[mask].sort_values(by = 'score', ascending = False)\n",
        "\n",
        "    def top_lsvr(self):\n",
        "        scaler_type = [StandardScaler, MinMaxScaler, RobustScaler]\n",
        "        grid_k = {}\n",
        "        for s in scaler_type:\n",
        "            pipe = Pipeline([('scale', s()),\n",
        "                            ('classify' , LinearSVR(random_state=42))\n",
        "                            ])\n",
        "\n",
        "            hyperparams = {\n",
        "                            'classify__C': np.arange(0.5, 3.5,0.5)\n",
        "                        }\n",
        "            grid_k[\"grid_\" + s.__name__] = GridSearchCV(pipe, hyperparams, cv=10, scoring='r2').fit(self.X_m, self.y_m)\n",
        "        res1 = grid_k[\"grid_StandardScaler\"].cv_results_\n",
        "        df1 = pd.DataFrame(res1['params'])\n",
        "        df1['score'] = res1['mean_test_score']\n",
        "        df1['scale'] = 'standard'\n",
        "\n",
        "        res2 = grid_k[\"grid_MinMaxScaler\"].cv_results_\n",
        "        df2 = pd.DataFrame(res2['params'])\n",
        "        df2['score'] = res2['mean_test_score']\n",
        "        df2['scale'] = 'min_max'\n",
        "\n",
        "\n",
        "        res3 = grid_k[\"grid_RobustScaler\"].cv_results_\n",
        "        df3 = pd.DataFrame(res3['params'])\n",
        "        df3['score'] = res3['mean_test_score']\n",
        "        df3['scale'] = 'robust'\n",
        "\n",
        "        res = [df1, df2, df3]\n",
        "        df = pd.concat(res, ignore_index = True)\n",
        "\n",
        "        M = df['score'].quantile(q = 0.95)\n",
        "        mask = df['score'] > M\n",
        "        return df[mask].sort_values(by = 'score', ascending = False)\n",
        "\n",
        "    def top_las(self):\n",
        "        scaler_type = [StandardScaler, MinMaxScaler, RobustScaler]\n",
        "        grid_k = {}\n",
        "        for s in scaler_type:\n",
        "            pipe = Pipeline([('scale', s()),\n",
        "                            ('classify'  , Lasso(normalize=False, random_state=42))\n",
        "                            ])\n",
        "\n",
        "            hyperparams = {\n",
        "                        'classify__alpha' : np.linspace(0.2, 2, 9)\n",
        "                        }\n",
        "            grid_k[\"grid_\" + s.__name__] = GridSearchCV(pipe, hyperparams, cv=10, scoring='r2').fit(self.X_m, self.y_m)\n",
        "        res1 = grid_k[\"grid_StandardScaler\"].cv_results_\n",
        "        df1 = pd.DataFrame(res1['params'])\n",
        "        df1['score'] = res1['mean_test_score']\n",
        "        df1['scale'] = 'standard'\n",
        "\n",
        "        res2 = grid_k[\"grid_MinMaxScaler\"].cv_results_\n",
        "        df2 = pd.DataFrame(res2['params'])\n",
        "        df2['score'] = res2['mean_test_score']\n",
        "        df2['scale'] = 'min_max'\n",
        "\n",
        "        res3 = grid_k[\"grid_RobustScaler\"].cv_results_\n",
        "        df3 = pd.DataFrame(res3['params'])\n",
        "        df3['score'] = res3['mean_test_score']\n",
        "        df3['scale'] = 'robust'\n",
        "\n",
        "        res = [df1, df2, df3]\n",
        "        df = pd.concat(res, ignore_index = True)\n",
        "        M = df['score'].quantile(q = 0.95)\n",
        "        mask = df['score'] > M\n",
        "        return df[mask].sort_values(by = 'score', ascending = False)\n",
        "\n",
        "    def top_ridge(self):\n",
        "            scaler_type = [StandardScaler, MinMaxScaler, RobustScaler]\n",
        "            grid_k = {}\n",
        "            for s in scaler_type:\n",
        "                pipe = Pipeline([('scale', s()),\n",
        "                                ('classify'  , Ridge(normalize=False, random_state=42))\n",
        "                                ])\n",
        "\n",
        "                hyperparams = {\n",
        "                            'classify__alpha' : np.linspace(0.2, 2, 9)\n",
        "                            }\n",
        "                grid_k[\"grid_\" + s.__name__] = GridSearchCV(pipe, hyperparams, cv=10, scoring='r2').fit(self.X_m, self.y_m)\n",
        "            res1 = grid_k[\"grid_StandardScaler\"].cv_results_\n",
        "            df1 = pd.DataFrame(res1['params'])\n",
        "            df1['score'] = res1['mean_test_score']\n",
        "            df1['scale'] = 'standard'\n",
        "\n",
        "            res2 = grid_k[\"grid_MinMaxScaler\"].cv_results_\n",
        "            df2 = pd.DataFrame(res2['params'])\n",
        "            df2['score'] = res2['mean_test_score']\n",
        "            df2['scale'] = 'min_max'\n",
        "\n",
        "            res3 = grid_k[\"grid_RobustScaler\"].cv_results_\n",
        "            df3 = pd.DataFrame(res3['params'])\n",
        "            df3['score'] = res3['mean_test_score']\n",
        "            df3['scale'] = 'robust'\n",
        "\n",
        "            res = [df1, df2, df3]\n",
        "            df = pd.concat(res, ignore_index = True)\n",
        "            M = df['score'].quantile(q = 0.95)\n",
        "            mask = df['score'] > M\n",
        "            return df[mask].sort_values(by = 'score', ascending = False)\n",
        "\n",
        "    def best_model(self):\n",
        "        knr_model = self.top_knr()\n",
        "        knr_model['model'] = 'knr'\n",
        "        rfr_model = self.top_rfr()\n",
        "        rfr_model['model'] = 'rfr'\n",
        "        lsvr_model = self.top_lsvr()\n",
        "        lsvr_model['model'] = 'lsvr'\n",
        "        las_model = self.top_las()\n",
        "        las_model['model'] = 'lasso'\n",
        "        ridge_model = self.top_ridge()\n",
        "        ridge_model['model'] = 'ridge'\n",
        "\n",
        "        mask1 = knr_model['score'] == knr_model['score'].max()\n",
        "        mask2 = rfr_model['score'] == rfr_model['score'].max()\n",
        "        mask3 = lsvr_model['score'] == lsvr_model['score'].max()\n",
        "        mask4 = las_model['score'] == las_model['score'].max()\n",
        "        mask5 = ridge_model['score'] == ridge_model['score'].max()\n",
        "\n",
        "        full_model = [knr_model[mask1], rfr_model[mask2], lsvr_model[mask3], las_model[mask4], ridge_model[mask5]]\n",
        "        first_highest_score = [knr_model[mask1]['score'].iloc[0], \n",
        "                               rfr_model[mask2]['score'].iloc[0], \n",
        "                               lsvr_model[mask3]['score'].iloc[0], \n",
        "                               las_model[mask4]['score'].iloc[0], \n",
        "                               ridge_model[mask5]['score'].iloc[0]]\n",
        "        return full_model[np.argmax(first_highest_score)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "lA4C1NqO_21g",
        "outputId": "f1c8b772-bd76-4b59-cde5-68e4a2eabd4f"
      },
      "source": [
        "TopModel_Regressor(X_lat_m, y_lat_m).best_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classify__max_depth</th>\n",
              "      <th>score</th>\n",
              "      <th>scale</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.01178</td>\n",
              "      <td>standard</td>\n",
              "      <td>rfr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   classify__max_depth    score     scale model\n",
              "0                    2  0.01178  standard   rfr"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "zZGVLAbmlRkc",
        "outputId": "84f97049-fef3-4e7b-8b73-2a8b7dd909aa"
      },
      "source": [
        "TopModel_Regressor(X_yr_m, y_yr_m).best_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classify__max_depth</th>\n",
              "      <th>score</th>\n",
              "      <th>scale</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>8</td>\n",
              "      <td>0.033497</td>\n",
              "      <td>robust</td>\n",
              "      <td>rfr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    classify__max_depth     score   scale model\n",
              "13                    8  0.033497  robust   rfr"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5BHcCD0OFUC"
      },
      "source": [
        "Result Summary: \n",
        "- The best model for predicting the region where the Monarch butterfly was collected was the Random Forest classifier which applied a max depth of 8 decision trees and in which the data was scaled by the robust scaler. \n",
        "\n",
        "- The best model for predicting the country where the Monarch butterfly was collected was the K-Nearest Neighbors classifier which applied the uniform weight function and 20 neighbors and in which the data was scaled by the min-max scaler. \n",
        "\n",
        "- The best model for predicting the latitude in North America where the Monarch butterfly was originally from was the Random Forest regressor which applied a max depth of 2 decision trees and in which the data was scaled by the standard scaler. \n",
        "\n",
        "- The best model for predicting the year when the Monarch butterfly was collected was the Random Forest regressor which applied a max depth of 8 decision trees and in which the data was scaled by the robust scaler. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e92OMaCn2AwU"
      },
      "source": [
        "## Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLsY-4fWS8ML"
      },
      "source": [
        "Using the best models found in the last section, their performance on the holdout sets were evaluated using weighted $F1$-score and the $R^2$ score for the classifiers and regressors, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "raZcjpZrJFfC",
        "outputId": "0430cd02-b96e-4eef-e771-bfe70ed0a374"
      },
      "source": [
        "#Best model for for predicting region based on physical traits\n",
        "pipe = Pipeline([('scale', RobustScaler()),\n",
        "                ('classify', RandomForestClassifier(max_depth=8, random_state=42))\n",
        "                ])\n",
        "y_true = y_reg_h\n",
        "y_pred = pipe.fit(X_reg_m,y_reg_m).predict(X_reg_h) \n",
        "reg_f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "pd.DataFrame([reg_f1], columns=['Weighted F1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.400797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Weighted F1\n",
              "0     0.400797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "GqFtkQgRLEJV",
        "outputId": "5e050a3e-e4fc-44d8-8791-e290aa909b21"
      },
      "source": [
        "#Best model for for predicting country based on physical traits\n",
        "pipe = Pipeline([('scale', MinMaxScaler()),\n",
        "                ('classify', KNeighborsClassifier(n_neighbors=20, weights='uniform'))\n",
        "                ])\n",
        "y_true = y_ctry_h\n",
        "y_pred = pipe.fit(X_ctry_m,y_ctry_m).predict(X_ctry_h) \n",
        "ctry_f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "pd.DataFrame([ctry_f1], columns=['Weighted F1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.220113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Weighted F1\n",
              "0     0.220113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "hrD4QEcmMl4z",
        "outputId": "de2b1621-f0ee-4957-e3b1-d06b555626a1"
      },
      "source": [
        "#Best model for predicting the origin of migratory butterflies in North America based on physical traits\n",
        "pipe = Pipeline([('scale', StandardScaler()),\n",
        "                ('classify', RandomForestRegressor(max_depth=2, random_state=42))\n",
        "                ])\n",
        "y_true = y_lat_h\n",
        "y_pred = pipe.fit(X_lat_m,y_lat_m).predict(X_lat_h) \n",
        "lat_R2 = r2_score(y_true, y_pred)\n",
        "pd.DataFrame([lat_R2], columns=['R2'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.000482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         R2\n",
              "0 -0.000482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "6ueEqWAtMppo",
        "outputId": "0cfa94fb-44be-4ee2-8974-296bbee0693b"
      },
      "source": [
        "#Best model for predicting the origin of migratory butterflies in North America based on physical traits\n",
        "pipe = Pipeline([('scale', StandardScaler()),\n",
        "                ('classify', RandomForestRegressor(max_depth=8, random_state=42))\n",
        "                ])\n",
        "y_true = y_yr_h\n",
        "y_pred = pipe.fit(X_yr_m,y_yr_m).predict(X_yr_h) \n",
        "yr_R2 = r2_score(y_true, y_pred)\n",
        "pd.DataFrame([yr_R2], columns=['R2'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.037975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         R2\n",
              "0  0.037975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2vPr-BxfPJV"
      },
      "source": [
        "The models applied to the holdout sets for *Aedes aegypti* and both species had positive results. The R squared value suggests that around 43% of the variance of the mosquito counts can be explained by the model. In additions to this, the RMSE suggests that the model deviated on average by around 7 mosquitoes from the true counts. One issue that may come from this model is the maximum depth for the Random Forest Regressor. Normally, components of random forests, decision trees, tend to overfit when the maximum depth of these trees is too high. For that reason, there may be some issues in regards to generalizing this model to future data points.  \n",
        "\n",
        "The model applied to the holdout set for *Aedes albopictus* did relatively poorly. Although the RMSE suggests that the model deviated on average by around 1 mosquito from the true counts, the R squared value suggest that only around 3% of the variance of the mosquito counts can be explained by the model. This is likely due to underfitting since the K-Nearest Neighbors algorithm tends to underfit the data as the number of neighbors increases. Another factor that may have played a part in this score is the fact that most of the data values for this species was 0. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lHG-RwJwRVL"
      },
      "source": [
        "## Optimization and Other Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A87u_yIu02dC"
      },
      "source": [
        "X_reg = df_reg[['LLength', 'LWidth', 'LArea', 'LPerimeter', 'RLength', 'RWidth', 'RArea', 'RPerimeter','Sex']]\n",
        "y_reg = df_reg['Region']\n",
        "\n",
        "holdout_frac = 0.20\n",
        "holdout_splitter = StratifiedShuffleSplit(test_size=holdout_frac, random_state=42)\n",
        "model_idx, holdout_idx = next(holdout_splitter.split(X_reg, y_reg))\n",
        "X_reg_m, y_reg_m = X_reg.iloc[model_idx]  , y_reg.iloc[model_idx]\n",
        "X_reg_h, y_reg_h = X_reg.iloc[holdout_idx], y_reg.iloc[holdout_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTHKbUvF1lF3"
      },
      "source": [
        "X_ctry = df_country[['LLength', 'LWidth', 'LArea', 'LPerimeter', 'RLength', 'RWidth', 'RArea', 'RPerimeter','Sex']]\n",
        "y_ctry = df_country['Country/Archipelago']\n",
        "\n",
        "holdout_frac = 0.20\n",
        "holdout_splitter = StratifiedShuffleSplit(n_splits = 5, test_size=holdout_frac, random_state=42)\n",
        "model_idx, holdout_idx = next(holdout_splitter.split(X_ctry, y_ctry))\n",
        "X_ctry_m, y_ctry_m = X_ctry.iloc[model_idx]  , y_ctry.iloc[model_idx]\n",
        "X_ctry_h, y_ctry_h = X_ctry.iloc[holdout_idx], y_ctry.iloc[holdout_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtFNzh87wogR"
      },
      "source": [
        "def top_knc(X_m, y_m):\n",
        "    pipe = Pipeline([('scale', MinMaxScaler()),\n",
        "                    ('classify'  , KNeighborsClassifier())\n",
        "                    ])\n",
        "\n",
        "    hyperparams = {\n",
        "                'classify__n_neighbors' : np.arange(1,26),\n",
        "                'classify__weights' : ['uniform', 'distance']\n",
        "                }\n",
        "    grid = GridSearchCV(pipe, hyperparams, cv=10, scoring='f1_weighted').fit(X_m, y_m)\n",
        "    res = grid.cv_results_\n",
        "    df = pd.DataFrame(res['params'])\n",
        "    df['score'] = res['mean_test_score']\n",
        "    df['scale'] = 'min_max'\n",
        "\n",
        "    M = df['score'].quantile(q = 0.9)\n",
        "    mask = df['score'] > M\n",
        "    return df[mask].sort_values(by = 'score', ascending = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qC23MkNx6OR"
      },
      "source": [
        "def top_rfc(X_m, y_m):\n",
        "    pipe = Pipeline([('scale', RobustScaler()),\n",
        "                    ('classify' , RandomForestClassifier(random_state=42))\n",
        "                    ])\n",
        "\n",
        "    hyperparams = {\n",
        "                'classify__max_depth' : np.arange(1, 15)\n",
        "                }\n",
        "    grid = GridSearchCV(pipe, hyperparams, cv=10, scoring='f1_weighted').fit(X_m, y_m)\n",
        "    res = grid.cv_results_\n",
        "    df = pd.DataFrame(res['params'])\n",
        "    df['score'] = res['mean_test_score']\n",
        "    df['scale'] = 'robust'\n",
        "\n",
        "    M = df['score'].quantile(q = 0.9)\n",
        "    mask = df['score'] > M\n",
        "    return df[mask].sort_values(by = 'score', ascending = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "_NucDI5yykxm",
        "outputId": "118fb2c3-0b65-47de-aa28-198d441fb07f"
      },
      "source": [
        "top_rfc(X_reg_m, y_reg_m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classify__max_depth</th>\n",
              "      <th>score</th>\n",
              "      <th>scale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>0.449846</td>\n",
              "      <td>robust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>0.449811</td>\n",
              "      <td>robust</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    classify__max_depth     score   scale\n",
              "10                   11  0.449846  robust\n",
              "13                   14  0.449811  robust"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "dhJusfhc0QdX",
        "outputId": "5ebc2fac-cb28-4a35-c405-d6b542f2df74"
      },
      "source": [
        "#Best optimized model for for predicting region based on physical traits\n",
        "pipe = Pipeline([('scale', RobustScaler()),\n",
        "                ('classify', RandomForestClassifier(max_depth=11, random_state=42))\n",
        "                ])\n",
        "y_true = y_reg_h\n",
        "y_pred = pipe.fit(X_reg_m,y_reg_m).predict(X_reg_h) \n",
        "reg_f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "pd.DataFrame([reg_f1], columns=['Weighted F1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.45947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Weighted F1\n",
              "0      0.45947"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3kdggJccy3ir",
        "outputId": "110a1fc8-022b-47af-c4c1-5fc78c7f52dc"
      },
      "source": [
        "top_knc(X_ctry_m, y_ctry_m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classify__n_neighbors</th>\n",
              "      <th>classify__weights</th>\n",
              "      <th>score</th>\n",
              "      <th>scale</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>11</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.233033</td>\n",
              "      <td>min_max</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>13</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.232536</td>\n",
              "      <td>min_max</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>14</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.231351</td>\n",
              "      <td>min_max</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>10</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.230556</td>\n",
              "      <td>min_max</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>22</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.230447</td>\n",
              "      <td>min_max</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    classify__n_neighbors classify__weights     score    scale\n",
              "20                     11           uniform  0.233033  min_max\n",
              "24                     13           uniform  0.232536  min_max\n",
              "26                     14           uniform  0.231351  min_max\n",
              "18                     10           uniform  0.230556  min_max\n",
              "42                     22           uniform  0.230447  min_max"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "zpqtfclP0k6q",
        "outputId": "6ff8f56e-01c7-43d2-d18a-2cfa9b46f044"
      },
      "source": [
        "#Best optimized model for for predicting country based on physical traits\n",
        "pipe = Pipeline([('scale', MinMaxScaler()),\n",
        "                ('classify', KNeighborsClassifier(n_neighbors=11, weights='uniform'))\n",
        "                ])\n",
        "y_true = y_ctry_h\n",
        "y_pred = pipe.fit(X_ctry_m,y_ctry_m).predict(X_ctry_h) \n",
        "ctry_f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "pd.DataFrame([ctry_f1], columns=['Weighted F1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.238106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Weighted F1\n",
              "0     0.238106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGOca3xy_ftQ"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSnehxaqBtYf"
      },
      "source": [
        "reg_class = df_reg['Region'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZZPagn-Q-wB"
      },
      "source": [
        "df_reg_shuffle = pd.concat([X_reg_m, y_reg_m], axis = 1)\n",
        "df_reg_shuffle['Region'] = pd.Categorical(df_reg_shuffle['Region'])\n",
        "df_reg_shuffle['Region'] = df_reg_shuffle.Region.cat.codes\n",
        "y_reg_m = df_reg_shuffle.pop('Region')\n",
        "X_reg_m = df_reg_shuffle\n",
        "\n",
        "df_reg_shuffle = pd.concat([X_reg_h, y_reg_h], axis = 1)\n",
        "df_reg_shuffle['Region'] = pd.Categorical(df_reg_shuffle['Region'])\n",
        "df_reg_shuffle['Region'] = df_reg_shuffle.Region.cat.codes\n",
        "y_reg_h = df_reg_shuffle.pop('Region')\n",
        "X_reg_h = df_reg_shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_cL9qXVQIG7"
      },
      "source": [
        "data_reg_neural_m = tf.data.Dataset.from_tensor_slices((X_reg_m.values, y_reg_m.values))\n",
        "train_dataset = data_reg_neural_m.shuffle(len(X_reg_m)).batch(1)\n",
        "\n",
        "data_reg_neural_h = tf.data.Dataset.from_tensor_slices((X_reg_h.values, y_reg_h.values))\n",
        "holdout_dataset = data_reg_neural_h.shuffle(len(X_reg_h)).batch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkHYcJ9QSeqI"
      },
      "source": [
        "def get_compiled_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(12, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "                metrics=['categorical_accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDjJYk_DTK2k",
        "outputId": "5b91bb9c-83f8-4ed4-d306-1fc20717e394"
      },
      "source": [
        "model = get_compiled_model()\n",
        "model.fit(train_dataset, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "5271/5271 [==============================] - 6s 1ms/step - loss: 3.7898e-07 - categorical_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "5271/5271 [==============================] - 5s 1ms/step - loss: 3.7800e-07 - categorical_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "5271/5271 [==============================] - 5s 1ms/step - loss: 3.7822e-07 - categorical_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc457f7b6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEtwafEsY5Lu",
        "outputId": "7084920a-6268-4bd1-e8d1-7740c1882813"
      },
      "source": [
        "model.evaluate(holdout_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1318/1318 [==============================] - 1s 748us/step - loss: 3.7843e-07 - categorical_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.784307125442865e-07, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsuBHOn6rsok"
      },
      "source": [
        "df_ctry_shuffle = pd.concat([X_ctry_m, y_ctry_m], axis = 1)\n",
        "df_ctry_shuffle['Country/Archipelago'] = pd.Categorical(df_ctry_shuffle['Country/Archipelago'])\n",
        "df_ctry_shuffle['Country/Archipelago'] = df_ctry_shuffle['Country/Archipelago'].cat.codes\n",
        "y_ctry_m = df_ctry_shuffle.pop('Country/Archipelago')\n",
        "X_ctry_m = df_ctry_shuffle\n",
        "\n",
        "df_ctry_shuffle = pd.concat([X_ctry_h, y_ctry_h], axis = 1)\n",
        "df_ctry_shuffle['Country/Archipelago'] = pd.Categorical(df_ctry_shuffle['Country/Archipelago'])\n",
        "df_ctry_shuffle['Country/Archipelago'] = df_ctry_shuffle['Country/Archipelago'].cat.codes\n",
        "y_ctry_h = df_ctry_shuffle.pop('Country/Archipelago')\n",
        "X_ctry_h = df_ctry_shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-zfohOmuQQz"
      },
      "source": [
        "data_ctry_neural_m = tf.data.Dataset.from_tensor_slices((X_ctry_m.values, y_ctry_m.values))\n",
        "train_dataset = data_ctry_neural_m.shuffle(len(X_ctry_m)).batch(1)\n",
        "\n",
        "data_ctry_neural_h = tf.data.Dataset.from_tensor_slices((X_ctry_h.values, y_ctry_h.values))\n",
        "holdout_dataset = data_ctry_neural_h.shuffle(len(X_ctry_h)).batch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bgeN0w2vOts",
        "outputId": "1146da3d-71f2-4f8b-ba32-9ac03da2a32c"
      },
      "source": [
        "model = get_compiled_model()\n",
        "model.fit(train_dataset, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "5233/5233 [==============================] - 6s 1ms/step - loss: 3.1985e-06 - categorical_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "5233/5233 [==============================] - 5s 1ms/step - loss: 3.1682e-06 - categorical_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "5233/5233 [==============================] - 5s 1ms/step - loss: 3.1861e-06 - categorical_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "5233/5233 [==============================] - 5s 1ms/step - loss: 3.1210e-06 - categorical_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "5233/5233 [==============================] - 5s 1ms/step - loss: 3.2347e-06 - categorical_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc453803e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sAHU5GZvSZ8",
        "outputId": "a568f5f9-78bb-44e4-cc33-532a133e7584"
      },
      "source": [
        "model.evaluate(holdout_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1309/1309 [==============================] - 1s 726us/step - loss: 3.1803e-06 - categorical_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.1803108413441805e-06, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg22sj6s2Iw1"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a20ILsLul7-C"
      },
      "source": [
        "In this project, the data collected on the number of mosquitoes for two different species caught in traps throughout Brownsville, TX, was explored. By applying three different regression algorithms, the number of mosquitoes was predicted from ecological and meteorological variables. Overall, it was shown that the Random Forest regressor gave the best results when applied to the *Aedes aegypti* species and to both species collectively. However, the best model calculated for the *Aedes albopictus* species performed poorly with respect to the R squared score likely due to underfitting. These results are summarized in the tables and charts below.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "oOIsQ1jUJzev",
        "outputId": "830fbaa8-921d-4eb3-c04f-0b105e822ed4"
      },
      "source": [
        "aeg_model_best_rev = aeg_model_best.rename(columns={'classify__max_depth': 'max depth',\n",
        "                                                    'dim_reduce__n_components': 'reduced dimension',\n",
        "                                                    'score': 'R2 score'})\n",
        "aeg_model_best_rev.at[0,'model'] = 'random forest'\n",
        "aeg_model_best_rev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>max depth</th>\n",
              "      <th>reduced dimension</th>\n",
              "      <th>R2 score</th>\n",
              "      <th>scale</th>\n",
              "      <th>model</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>0.388783</td>\n",
              "      <td>robust</td>\n",
              "      <td>random forest</td>\n",
              "      <td>aeg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   max depth  reduced dimension  R2 score   scale          model species\n",
              "0         10                 15  0.388783  robust  random forest     aeg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "Bom4GlqcJ2QQ",
        "outputId": "73cc27ab-d269-4bbf-b01e-b14c91279dfa"
      },
      "source": [
        "alb_model_best_rev = alb_model_best.rename(columns={'classify__n_neighbors': 'neighbors',\n",
        "                                                    'classify__weights': 'weight',\n",
        "                                                    'dim_reduce__n_components': 'reduced dimension',\n",
        "                                                    'score': 'R2 score'})\n",
        "alb_model_best_rev.at[0,'model'] = 'k-nearest neighbors'\n",
        "alb_model_best_rev\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>neighbors</th>\n",
              "      <th>weight</th>\n",
              "      <th>reduced dimension</th>\n",
              "      <th>R2 score</th>\n",
              "      <th>scale</th>\n",
              "      <th>model</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>uniform</td>\n",
              "      <td>10</td>\n",
              "      <td>0.277847</td>\n",
              "      <td>standard</td>\n",
              "      <td>k-nearest neighbors</td>\n",
              "      <td>alb</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   neighbors   weight  reduced dimension  R2 score     scale  \\\n",
              "0         15  uniform                 10  0.277847  standard   \n",
              "\n",
              "                 model species  \n",
              "0  k-nearest neighbors     alb  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "kVODy2IDJ2wX",
        "outputId": "030bede5-e5f3-4b51-91ac-3ece89d1ca45"
      },
      "source": [
        "tot_model_best_rev = aeg_model_best.rename(columns={'classify__max_depth': 'max depth',\n",
        "                                                    'dim_reduce__n_components': 'reduced dimension',\n",
        "                                                    'score': 'R2 score'})\n",
        "tot_model_best_rev.at[0,'model'] = 'random forest'\n",
        "tot_model_best_rev.at[0,'species'] = 'both'\n",
        "tot_model_best_rev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>max depth</th>\n",
              "      <th>reduced dimension</th>\n",
              "      <th>R2 score</th>\n",
              "      <th>scale</th>\n",
              "      <th>model</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>0.388783</td>\n",
              "      <td>robust</td>\n",
              "      <td>random forest</td>\n",
              "      <td>both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   max depth  reduced dimension  R2 score   scale          model species\n",
              "0         10                 15  0.388783  robust  random forest    both"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOwg1O9S6QJE"
      },
      "source": [
        "![R2_scores.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axhQqyjs89nh"
      },
      "source": [
        "If there was more time to pursue this project, the performance of the second best models could be considered. In addition, Support Vector Machine regression, Ridge regression, and Elastic-Net regression are other models that could be applied to the dataset as well. The application of other ensemble methods such as Gradient Boosting regression to the data set is an option that could be explored as well. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "932uJXD12LgV"
      },
      "source": [
        "## References\n",
        "- Freedman, M. G., Dingle, H., Strauss, S. Y., & Ramírez, S. R. (2020). Two centuries of monarch butterfly collections reveal contrasting effects of range expansion and migration loss on wing traits. *Proceedings of the National Academy of Sciences, 117*(46), 28887-28893.\n"
      ]
    }
  ]
}